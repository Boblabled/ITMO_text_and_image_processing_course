{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-08T10:42:45.513852Z",
     "start_time": "2025-06-08T10:42:45.488184Z"
    }
   },
   "source": [
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "model = YOLO('yolo11n.pt')"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T10:46:34.200966Z",
     "start_time": "2025-06-08T10:46:34.198479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DATA_PATH = \"data\\\\Task_1\"\n",
    "images = []\n",
    "for path, dirs, files in os.walk(DATA_PATH):\n",
    "    for file in files:\n",
    "        images.append(os.path.join(path, file))\n",
    "        "
   ],
   "id": "ef66358d3fad8916",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T10:52:34.914337Z",
     "start_time": "2025-06-08T10:52:31.135709Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for image in images:\n",
    "    model(Image.open(image),  conf=0.8, show=True, save=True)"
   ],
   "id": "f752e70adef5bf2e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 416x640 (no detections), 28.3ms\n",
      "Speed: 1.1ms preprocess, 28.3ms inference, 0.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "Results saved to \u001B[1mC:\\Users\\Yo\\PycharmProjects\\University\\ITMO_text_and_image_processing_course\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "0: 448x640 4 persons, 23.2ms\n",
      "Speed: 1.2ms preprocess, 23.2ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Results saved to \u001B[1mC:\\Users\\Yo\\PycharmProjects\\University\\ITMO_text_and_image_processing_course\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "0: 448x640 2 persons, 1 dog, 23.1ms\n",
      "Speed: 1.2ms preprocess, 23.1ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Results saved to \u001B[1mC:\\Users\\Yo\\PycharmProjects\\University\\ITMO_text_and_image_processing_course\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "0: 448x640 4 persons, 23.7ms\n",
      "Speed: 1.0ms preprocess, 23.7ms inference, 0.9ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Results saved to \u001B[1mC:\\Users\\Yo\\PycharmProjects\\University\\ITMO_text_and_image_processing_course\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "0: 448x640 6 persons, 22.5ms\n",
      "Speed: 1.1ms preprocess, 22.5ms inference, 0.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Results saved to \u001B[1mC:\\Users\\Yo\\PycharmProjects\\University\\ITMO_text_and_image_processing_course\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "0: 448x640 4 persons, 25.6ms\n",
      "Speed: 1.2ms preprocess, 25.6ms inference, 0.9ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Results saved to \u001B[1mC:\\Users\\Yo\\PycharmProjects\\University\\ITMO_text_and_image_processing_course\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "0: 448x640 4 persons, 22.0ms\n",
      "Speed: 1.1ms preprocess, 22.0ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Results saved to \u001B[1mC:\\Users\\Yo\\PycharmProjects\\University\\ITMO_text_and_image_processing_course\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "0: 384x640 5 persons, 25.6ms\n",
      "Speed: 1.1ms preprocess, 25.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mC:\\Users\\Yo\\PycharmProjects\\University\\ITMO_text_and_image_processing_course\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "0: 448x640 2 persons, 25.0ms\n",
      "Speed: 1.1ms preprocess, 25.0ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Results saved to \u001B[1mC:\\Users\\Yo\\PycharmProjects\\University\\ITMO_text_and_image_processing_course\\runs\\detect\\predict\u001B[0m\n",
      "\n",
      "0: 544x640 1 person, 24.3ms\n",
      "Speed: 1.7ms preprocess, 24.3ms inference, 0.7ms postprocess per image at shape (1, 3, 544, 640)\n",
      "Results saved to \u001B[1mC:\\Users\\Yo\\PycharmProjects\\University\\ITMO_text_and_image_processing_course\\runs\\detect\\predict\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T11:02:38.244304Z",
     "start_time": "2025-06-08T11:02:38.241306Z"
    }
   },
   "cell_type": "code",
   "source": [
    "TP = 2 + 4 + 6 + 4 + 4 + 5 + 2 + 1 + 4\n",
    "FP = 0\n",
    "FN = 4 + 2 + 1 + 1 + 2 + 3\n",
    "TN = 0\n",
    "print(\"TP:\", TP)\n",
    "print(\"FP:\", FP)\n",
    "print(\"FN:\", FN)\n",
    "print(\"TN:\", TN)"
   ],
   "id": "197f19ac32716a7a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 32\n",
      "FP: 0\n",
      "FN: 13\n",
      "TN: 0\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "P.S. Очень жаль что авторы дауны, и надо руками считать 10 изображений",
   "id": "1c84075a81f51d0d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T11:03:09.709082Z",
     "start_time": "2025-06-08T11:03:09.705919Z"
    }
   },
   "cell_type": "code",
   "source": [
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "f1_score = 2 * precision * recall / (precision + recall)\n",
    "print(\"%.3f\" % f1_score)"
   ],
   "id": "e36dbe8364d1433c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.831\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
