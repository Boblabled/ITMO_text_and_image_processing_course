{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vd_ST0GfO97y"
      },
      "source": [
        "# Информационный поиск\n",
        "\n",
        "Скачиваем классический набор данных -- набор текстов об аэронавтике CRANFIELD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHflLH2APAHK",
        "outputId": "6d2dadcc-9af6-4deb-d4bd-dc04b00913be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cran.all.1400\n",
            "cran.qry\n",
            "cranqrel\n",
            "cranqrel.readme\n"
          ]
        }
      ],
      "source": [
        "! wget -q http://ir.dcs.gla.ac.uk/resources/test_collections/cran/cran.tar.gz\n",
        "! tar -xvf cran.tar.gz\n",
        "! rm cran.tar.gz*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYuND83cPR5D"
      },
      "source": [
        "Берём только сами запросы (это будут наши документы)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6owW-L7zhJws",
        "outputId": "4954a94c-b8ab-4259-f357-da81ac72a63d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "what similarity laws must be obeyed when constructing aeroelastic models\r\n",
            "of heated high speed aircraft .\r\n",
            "what are the structural and aeroelastic problems associated with flight\r\n"
          ]
        }
      ],
      "source": [
        "! grep -v \"^\\.\" cran.qry > just.qry\n",
        "! head -3 just.qry"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZbUb6FmQxr1"
      },
      "source": [
        "Объединяем многострочные в один"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBaV3xeQiUam",
        "outputId": "2e5744c9-d9e9-4b29-bf4f-12bf0eceeb2c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['what similarity laws must be obeyed when constructing aeroelastic models of heated high speed aircraft . ',\n",
              " 'what are the structural and aeroelastic problems associated with flight of high speed aircraft . ']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "raw_query_data = [line.strip() for line in open(\"just.qry\", \"r\").readlines()]\n",
        "query_data = [\"\"]\n",
        "\n",
        "for query_part in raw_query_data:\n",
        "  query_data[-1] += query_part + \" \"\n",
        "  if query_part.endswith(\".\"):\n",
        "    query_data.append(\"\")\n",
        "\n",
        "query_data[:2] #Выведем пару документов для примера"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLFq_6lBki3S"
      },
      "source": [
        "### Составим запросы к нашим документам"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "h3sgHjWkjjR1"
      },
      "outputs": [],
      "source": [
        "# QUERIES = ['theory of bending', 'aeroelastic effects']\n",
        "QUERIES = ['unsteady aerodynamics']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQMdH0HSkoJg"
      },
      "source": [
        "## Boolean retrieval\n",
        "Представим каждый документ как \"битовую маску\": вектор размером со словарь, в котором на каждой позиции единица, если в документе есть соответсвующий терм, и ноль, если терма нет"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhrI18rZSLLz",
        "outputId": "b8a28222-ce45-448c-e486-c00fec2e14dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for scikit-learn (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for scikit-learn\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (scikit-learn)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# в разных версиях ответы могут отличаться, поэтому важно иметь одну и ту же\n",
        "! pip install -q scikit-learn==0.22.2.post1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbTOdsHIknD0",
        "outputId": "5b7a07c8-03a9-48ed-a51c-d30accf24da4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['what', 'similarity', 'laws']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "from  sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "encoder = CountVectorizer(binary=True)\n",
        "encoded_data = encoder.fit_transform(query_data)\n",
        "encoded_queries = encoder.transform(QUERIES)\n",
        "list(encoder.vocabulary_)[:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUdwKDKSTjdD"
      },
      "source": [
        "Посмотрим на представление первого предложения"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXEmXErylJdX",
        "outputId": "6730e465-8b41-4201-ccdf-c080749dbd9b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['what',\n",
              " 'similarity',\n",
              " 'laws',\n",
              " 'must',\n",
              " 'be',\n",
              " 'obeyed',\n",
              " 'when',\n",
              " 'constructing',\n",
              " 'aeroelastic',\n",
              " 'models',\n",
              " 'of',\n",
              " 'heated',\n",
              " 'high',\n",
              " 'speed',\n",
              " 'aircraft']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "id2term = {idx: term for term, idx in encoder.vocabulary_.items()}\n",
        "non_zero_values_ids = encoded_data[0].nonzero()[1]\n",
        "\n",
        "terms = [id2term[idx] for idx in non_zero_values_ids]\n",
        "terms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8wdS9XiVwb2"
      },
      "source": [
        "Всё так.\n",
        "\n",
        "## Задание 0\n",
        "\n",
        "Теперь для каждого из данных запросов `QUERIES` найдём ближайший для него документ из `query_data` по сходству Жаккара. Есть более эффективные способы это сделать, но вам требуется реализовать расстояние Жаккара и далее применить его к нашим данным."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "u31WuBYAUWt2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def jaccard_sim(vector_a: np.array, vector_b: np.array) -> float:\n",
        "  \"\"\"\n",
        "    Сходство или коэффициент Жаккара: отношение мощности пересечения\n",
        "    к мощности объединения\n",
        "  \"\"\"\n",
        "  # ваш код здесь\n",
        "  intersection = np.logical_and(vector_a, vector_b).sum()\n",
        "  union = np.logical_or(vector_a, vector_b).sum()\n",
        "\n",
        "  return 0.0 if union == 0 else intersection / union\n",
        "#Проверка, что функция работает правильно\n",
        "assert jaccard_sim(np.array([1, 0, 1, 0, 1]), np.array([0, 1, 1, 1, 1])) == 0.4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_qlrbAQaqXC"
      },
      "source": [
        "Здесь документы представлены так же, как строки в матрице термов-документов. Каждая ячейка вектора отвечает за наличие/отсутствие конкретного элемента (например, слова-терма, когда у нас в словаре всего 5 слов). В первом случае их три, во втором — четыре. Объединение — все пять возможных элементов. Пересечение — два. Отсюда и 0.4."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYfQksWrOR1G"
      },
      "source": [
        "## Задание 1\n",
        "Теперь с помощью кода ниже вычислите для каждого запроса самые близкие документы."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4okpFpA6OAQs",
        "outputId": "fb9ed7bb-5581-4551-e2ac-4c24bb5c0dfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: unsteady aerodynamics\n",
            "FOUND:\n",
            "    22\t0.20\twhat progress has been made in research on unsteady aerodynamics . \n",
            "    95\t0.07\thas anyone investigated the unsteady lift distributions on finite wings in subsonic flow . \n",
            "    0\t0.00\twhat similarity laws must be obeyed when constructing aeroelastic models of heated high speed aircraft . \n"
          ]
        }
      ],
      "source": [
        "for q_id, query in enumerate(encoded_queries):\n",
        "  # приводим к нужному типу\n",
        "  query = query.todense().A1\n",
        "  docs = [doc.todense().A1 for doc in encoded_data]\n",
        "  # вычисляем коэфф. Жаккара\n",
        "  id2doc2similarity = [(doc_id, doc, jaccard_sim(query, doc)) for doc_id, doc in enumerate(docs)]\n",
        "  # сортируем по нему\n",
        "  closest = sorted(id2doc2similarity, key=lambda x: x[2], reverse=True)\n",
        "\n",
        "  print(\"Q: %s\\nFOUND:\" % QUERIES[q_id])\n",
        "  # выводим по 3 наиболее близких документа для каждого запроса\n",
        "  for closest_id, _, sim in closest[:3]:\n",
        "    print(\"    %d\\t%.2f\\t%s\" %(closest_id, sim, query_data[closest_id]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1Fh8RdvOrAD"
      },
      "source": [
        "Видим, что кое-где просачиваются  тексты, которых с запросами объединяют малозначительные термы, но при этом коэффициент Жаккара -- наша функция ранжирования! -- высок.\n",
        "\n",
        "# VSM\n",
        "\n",
        "Попробуем теперь сделать то же, но с tf-idf и косинусным расстоянием. Мы сделаем всё опять \"руками\", но \"в реальной жизни\" лучше использоватьесть эффективные реализации cosine distance, например, из библиотеки scipy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmpKMI08E2iO",
        "outputId": "664afd8e-5778-48a1-86f8-dad2b7c72a76"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['what', 'similarity', 'laws']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "from  sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Совет: обязательно разберитесь с тем, какие возможности\n",
        "# предоставляет tf-idf vectorizer, какие параметры за что отвечают\n",
        "\n",
        "tfidf_encoder = TfidfVectorizer()\n",
        "tfidf_encoded_data = tfidf_encoder.fit_transform(query_data)\n",
        "tfidf_encoded_queries = tfidf_encoder.transform(QUERIES)\n",
        "\n",
        "list(tfidf_encoder.vocabulary_)[:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHTzIjfNRHj2"
      },
      "source": [
        "## Задание 2\n",
        "Реализовать косинусное расстояние"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "UCfgR6xEPeDn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def cosine_distance(vector_a: np.array, vector_b: np.array) -> float:\n",
        "  \"\"\"\n",
        "    Косинусное расстояние: единица минус отношение скалярного произведения\n",
        "    на произведение L2-норм (подсказка: в numpy такие нормы есть)\n",
        "  \"\"\"\n",
        "  # ваш код здесь\n",
        "  cos_dist = np.linalg.norm(vector_a) * np.linalg.norm(vector_b)\n",
        "  cos_dist = 0.0 if cos_dist == 0.0 else np.dot(vector_a, vector_b) / cos_dist\n",
        "  cos_dist = 1 - cos_dist\n",
        "\n",
        "  return cos_dist\n",
        "#Проверка, что функция работает правильно\n",
        "assert cosine_distance(np.array([1, 0, 1, 1, 1]), np.array([0, 0, 1, 0, 0])) == 0.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJHsaHoORlEC"
      },
      "source": [
        "\n",
        "Теперь вычислим ближайшие по косинусному расстоянию между векторными представлениями документов и запросов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIZJRBKQQR1G",
        "outputId": "fa815506-0f8c-4ddb-9b7f-a5bf17346b77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: unsteady aerodynamics\n",
            "FOUND:\n",
            "    22\t0.41\twhat progress has been made in research on unsteady aerodynamics . \n",
            "    95\t0.74\thas anyone investigated the unsteady lift distributions on finite wings in subsonic flow . \n",
            "    0\t1.00\twhat similarity laws must be obeyed when constructing aeroelastic models of heated high speed aircraft . \n"
          ]
        }
      ],
      "source": [
        "for q_id, query in enumerate(tfidf_encoded_queries):\n",
        "\n",
        "  # приводим к нужному типу\n",
        "  query = query.todense().A1\n",
        "  docs = [doc.todense().A1 for doc in tfidf_encoded_data]\n",
        "  # Косинусное расстояние\n",
        "  id2doc2similarity = [(doc_id, doc, cosine_distance(query, doc)) \\\n",
        "                       for doc_id, doc in enumerate(docs)]\n",
        "  # сортируем по нему\n",
        "  closest = sorted(id2doc2similarity, key=lambda x: x[2], reverse=False)\n",
        "\n",
        "  print(\"Q: %s\\nFOUND:\" % QUERIES[q_id])\n",
        "\n",
        "  for closest_id, _, sim in closest[:3]:\n",
        "    print(\"    %d\\t%.2f\\t%s\" %(closest_id, sim, query_data[closest_id]))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}